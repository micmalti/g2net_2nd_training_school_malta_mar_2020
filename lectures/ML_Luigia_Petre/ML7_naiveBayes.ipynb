{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Naive Bayes\n",
    "\n",
    "- a classification algorithm\n",
    "- models are probabilistic distributions\n",
    "- general assumption\n",
    "    - data follows some *unknown* probabilistic distribution **D** over input/output pairs (x,y)\n",
    "- suppose we _know_ **D**\n",
    "    - we have a function _computeD(x,y)_ that returns the probability of pair (x,y) under **D**\n",
    "    - then, classification is simple\n",
    "        - **Bayes optimal classifier** $f^{BO}$ returns $y'$ for input $x'$ so that _computeD(x',y')_ is maximum possible\n",
    "        - returns $y'$ (e.g., the class) with the highest probability (likelihood)\n",
    "    - optimal: smallest error of all possible classifiers\n",
    "- we try to _estimate_ **D** with some **D'**, based on training set\n",
    "    - we hope **D** and **D'** are similar\n",
    "    - we use **D'** for classification\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes’ Theorem \n",
    "\n",
    "- provides a way to calculate the probability of some data belonging to a given class, given prior knowledge\n",
    "- <span style=\"color:blue\">P(class|data) = (P(data|class) * P(class)) / P(data)</span>\n",
    "\n",
    "Smoke and fire example: <span style=\"color:red\">**Fire => Smoke**</span>\n",
    "\n",
    "- What is the probability that there is fire given that there is smoke? \n",
    "\n",
    "Where <span style=\"color:blue\">P(Fire|Smoke)</span> is the **Posterior probability**, <span style=\"color:blue\">P(Fire)</span> is the **Prior probability**, <span style=\"color:blue\">P(Smoke|Fire)</span> is the **Likelihood**, and <span style=\"color:blue\">P(Smoke)</span> is the **Evidence**:\n",
    "\n",
    "- <span style=\"color:blue\">P(Fire|Smoke) = P(Smoke|Fire) * P(Fire) / P(Smoke)</span>\n",
    "- <span style=\"color:green\">**Posterior = Likelihood * Prior / Evidence**</span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A side example: diagnostic set\n",
    "\n",
    "Consider a population that might have or not the corona virus flu (<span style=\"color:blue\">Corona is T/F</span>) and a medical test that returns positive or negative for detecting corona (<span style=\"color:blue\">Test is T/F</span>) \n",
    "\n",
    "__Problem__: If a randomly selected patient has the test and it comes back positive, what is the probability that the patient has the virus?\n",
    "\n",
    "<span style=\"color:red\">P(Test=T | Corona=T) = 0.85</span> \n",
    "\n",
    "[Test: go to http://etc.ch/36Hx](https://directpoll.com/r?XDbzPBd3ixYqg8gh4tg26y59cvoG6LjOoN3TeIlKs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some calculations\n",
    "\n",
    "Test ignores the probability of a randomly selected person having corona, regardless of the results of a diagnostic test.\n",
    "\n",
    "- <span style=\"color:red\">P(Test=T | Corona=T) = 0.85</span>\n",
    "\n",
    "- <span style=\"color:red\">P(Corona=T) = 0.02</span>\n",
    "\n",
    "Bayes theorem: P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "- P(Corona=T | Test=T) = P(Test=T|Corona=T) * P(Corona=T) / P(Test=T)\n",
    "\n",
    "<span style=\"color:green\">**P(Corona=T | Test=T) = 0.85 * 0.0002 /** *P(Test=T*)</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### More calculations\n",
    "\n",
    "*P(B) = P(B|A) * P(A) + P(B|not A) * P(not A)*\n",
    "\n",
    "- P(Test=T) = P(Test=T|Corona=T) * P(Corona=T) + P(Test=T|Corona=F) * P(Corona=F)\n",
    "\n",
    "Firstly, we can calculate P(Corona=F) as the complement of P(Corona=T), which we already know\n",
    "\n",
    "- P(Corona=F) = 1 – P(Corona=T)\n",
    "= 1 – 0.0002\n",
    "= 0.9998\n",
    "\n",
    "Let’s plugin what we have:\n",
    "\n",
    "\n",
    "- <span style=\"color:green\">P(Test=T) = 0.85 * 0.0002 + *P(Test=T|Corona=F*) * 0.9998</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### More\n",
    "\n",
    "We need to know how good the test is at correctly identifying people that do not have corona. \n",
    "\n",
    "That is, testing negative (Test=F) when the patient does not have corona (Corona=F).\n",
    "\n",
    "We will use a contrived specificity value of 95%.\n",
    "\n",
    "P(Test=F | Corona=F) = 0.95\n",
    "\n",
    "P(Test=T|Corona=F) = 1 – P(Test=f | Corona=F)\n",
    "= 1 – 0.95\n",
    "= 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## So\n",
    "\n",
    "P(Test=T) = 0.85 * 0.0002 + 0.05 * 0.9998\n",
    "= 0.00017 + 0.04999\n",
    "= 0.05016\n",
    "\n",
    "<span style=\"color:green\">**P(Corona=T | Test=T) = 0.85 * 0.0002 /** *P(Test=T*)</span>\n",
    "\n",
    "= 0.85 * 0.0002 / 0.05016\n",
    "\n",
    "P(Corona = T | Test=T) = 0.00017 / 0.05016\n",
    "\n",
    "P(Corona = T | Test=T) = 0.003389154704944\n",
    "\n",
    "HENCE, if the patient is informed they have corona with this test, then there is only 0.33% chance that they do.\n",
    "\n",
    "It is a terrible diagnostic test!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Careful when dealing with these probabilities\n",
    "\n",
    "- Sensitivity: 85% of people with corona will get a positive test result.\n",
    "- Base Rate: 0.02% of people have corona.\n",
    "- Specificity: 95% of people without corona will get a negative test result.\n",
    "\n",
    "The rest of the entities had to be calculated.\n",
    "\n",
    "We might imagine that Bayes Theorem allows us to be even more precise about a given scenario. For example, if we had more information about the patient (e.g. their age) and about the domain (e.g. corona rates for age ranges), and in turn we could offer an even more accurate probability estimate.\n",
    "\n",
    "SO, how to use this theorem for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Classification\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the first 5 values of the dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Spliting the dataset in independent and dependent variables\n",
    "X = dataset.iloc[:,:4].values\n",
    "y = dataset[\"species\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Scaling to bring the variable in a single scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes Classification to the Training set with linear kernel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nvclassifier = GaussianNB()\n",
    "nvclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-virginica' 'Iris-virginica' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-versicolor']\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = nvclassifier.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Iris-virginica', 'Iris-virginica'],\n",
       "       ['Iris-virginica', 'Iris-virginica'],\n",
       "       ['Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa']], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets see the actual and predicted value side by side\n",
    "y_compare = np.vstack((y_test,y_pred)).T\n",
    "#actual value on the left side and predicted value on the right hand side\n",
    "#printing the top 5 values\n",
    "y_compare[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  1  9]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions:  28\n",
      "False predictions 2\n",
      "\n",
      "\n",
      "Accuracy of the Naive Bayes Clasification is:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#finding accuracy from the confusion matrix.\n",
    "a = cm.shape\n",
    "corrPred = 0\n",
    "falsePred = 0\n",
    "\n",
    "for row in range(a[0]):\n",
    "    for c in range(a[1]):\n",
    "        if row == c:\n",
    "            corrPred +=cm[row,c]\n",
    "        else:\n",
    "            falsePred += cm[row,c]\n",
    "print('Correct predictions: ', corrPred)\n",
    "print('False predictions', falsePred)\n",
    "print ('\\n\\nAccuracy of the Naive Bayes Clasification is: ', corrPred/(cm.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Probability for a single data point:\n",
    "- p(y,x) = p(y, x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>D</sub>)\n",
    "\n",
    "It's a distribution over a LOT of variables:\n",
    "- p(x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>D</sub>, y) = p(y) * p(x<sub>1</sub>|y) * p(x<sub>2</sub>|y,x<sub>1</sub>) * ... * p(x<sub>D</sub>|y,x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>D-1</sub>) = p(y) * $\\prod_{d} p(x_d|y,x_1, x_2, ..., x_{d-1})$\n",
    "\n",
    "Naive Bayes assumption\n",
    "- features are independent, conditioned on the label\n",
    "- $p(x_d|y,x_{d'})=p(x_d|y), \\forall d\\ne d'$\n",
    "- p(x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>D</sub>, y) = p(y) * p(x<sub>1</sub>|y) * p(x<sub>2</sub>|y,x<sub>1</sub>)...p(x<sub>D</sub>|y,x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>D-1</sub>) = p(y) * $\\prod_{d} p(x_d|y)$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
