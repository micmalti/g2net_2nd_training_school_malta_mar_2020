{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FineTuning a Pretrained Model to Distinguish Between Bees and Ants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this last but one section we will see how to perform the **fine tuning** of a pretrained model (for real, this time).\n",
    "To do this we will use a simpler dataset, composed by images belonging to just 2 classes, bees and ants.\n",
    "\n",
    "Finetuning means that we download and use a pretrained model as in the previous section, but instead of just training the newly added last layer, we should re-train *all* the model's parameters, but using a very low learning rate, in this way we won't change the parameters as much, but we'll permit our model to slowly adapt the parameters to the new task, thus the term FineTuning.\n",
    "\n",
    "Let's add our usual imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torchvision.datasets.mnist import FashionMNIST\n",
    "from torchvision.models.resnet import resnet18\n",
    "from torchvision import transforms, utils, datasets\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "let's create our dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform_tr = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "data_dir = '../data/hymenoptera_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "image_datasets_tr = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train'), \n",
    "    transform_tr)\n",
    "image_datasets_val = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'val'), \n",
    "    transform_val)\n",
    "\n",
    "dataloader_tr = data.DataLoader(image_datasets_tr, shuffle=True, batch_size=4, num_workers=4)\n",
    "dataloader_val = data.DataLoader(image_datasets_val, shuffle=False, batch_size=4, num_workers=4)\n",
    "\n",
    "dataset_sizes = {'train': len(image_datasets_tr), 'val': len(image_datasets_val)}\n",
    "\n",
    "class_names = image_datasets_tr.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "let's show some sample from the dataset and its label, for this purpose we will create a simple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    '''imshow for Tensor'''\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.array(std) * inp + np.array(mean)\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(inp)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(dataloader_tr))\n",
    "out = utils.make_grid(inputs)\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Bees, and also Ants.\n",
    "\n",
    "Let's get our pretrained model, replace the pooling layer and the last fc layer, we will also initialize the newly created fc layer weight data using a normal function having mu=0 and var=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True)\n",
    "# replace the avgpool (it's a 7x7 pooling expecting Cx7x7 tensors)\n",
    "model.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "# replace the last layer (it has 1000 out features and we need new weights)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model.fc.weight.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "we use a CrossEntropyLoss and SGD algorithm for classification as usual for classification problems. This time we will also make use of a *Learning Rate Scheduler*, which permits us to update the learning rate following a certain rule, in this case we will use the simple StepLR scheduler which accept a **step_size** parameter which corresponds to the amount of steps between each lr update, and a gamma parameter, which will get multiplied with our LR and the results will be our new LR.\n",
    "\n",
    "in brief the StepLR does:\n",
    "\n",
    "    every step_size steps:\n",
    "        LR *= gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer, \n",
    "    step_size=7, \n",
    "    gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's get our training started, as we don't want to wait and want to go drink some beer, we will train the model for just 1 epoch and evaluate the model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "\n",
    "    for i, (x, y) in enumerate(dataloader_tr):\n",
    "        l = loss(model(x), y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch: {}, batch_idx: {}/{}, loss: {}'.format(\n",
    "            epoch, i, len(dataloader_tr)-1, l.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Q: Why this time the pretrained model is training faster??\n",
    "\n",
    "because the dataset is much more small, in terms of number of samples, even if the images are much larger, we roughly have almost a 10% of its number of samples, thus the faster epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's evaluate the model on the validation dataset as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "ys = []\n",
    "for x, y in dataloader_val:\n",
    "    preds.extend(model(x).max(1)[1].data.tolist())\n",
    "    ys.extend(y.data)\n",
    "\n",
    "corrects = (np.array(preds) == np.array(ys))\n",
    "print('Accuracy: {}'.format(corrects.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "that's actually an awesome result with just one epoch of training. But let's count how many images the model classifies wrongly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print('correct predicitons: {}'.format(\n",
    "    np.sum(np.array(preds) == np.array(ys))))\n",
    "\n",
    "print('wrong predicitons: {}'.format(\n",
    "    np.sum(np.array(preds) != np.array(ys))))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
